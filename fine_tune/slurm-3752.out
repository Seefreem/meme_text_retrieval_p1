/var/spool/slurmd/job03752/slurm_script: line 6: hendrixgate02fl: command not found
0
Thu Sep 26 20:07:41 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN RTX               Off | 00000000:3D:00.0 Off |                  N/A |
| 41%   29C    P8              14W / 280W |      0MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
| distributed init (rank 0): env://
=> creating model: CLIP_VITL14_336
Distributed: True
=> loading latest checkpoint './output/checkpoint.pt'
=> loaded latest checkpoint './output/checkpoint.pt' (epoch 1)
=> creating dataset
  0%|          | 0/26224 [00:00<?, ?it/s]100%|██████████| 26224/26224 [00:00<00:00, 1777380.71it/s]
  0%|          | 0/1406 [00:00<?, ?it/s]100%|██████████| 1406/1406 [00:00<00:00, 1655584.34it/s]
  0%|          | 0/559 [00:00<?, ?it/s]100%|██████████| 559/559 [00:00<00:00, 1403121.45it/s]
/home/bjc154/.conda/envs/meme_text/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
dataset size: 26224
lr_schedule: 101 [1.00000000e-06 3.11111111e-06 5.22222222e-06 7.33333333e-06
 9.44444444e-06 1.15555556e-05 1.36666667e-05 1.57777778e-05
 1.78888889e-05 2.00000000e-05 2.00000000e-05 1.99970207e-05
 1.99880864e-05 1.99732076e-05 1.99524022e-05 1.99256949e-05
 1.98931176e-05 1.98547091e-05 1.98105151e-05 1.97605883e-05
 1.97049883e-05 1.96437812e-05 1.95770400e-05 1.95048443e-05
 1.94272801e-05 1.93444398e-05 1.92564222e-05 1.91633321e-05
 1.90652805e-05 1.89623842e-05 1.88547659e-05 1.87425537e-05
 1.86258815e-05 1.85048883e-05 1.83797182e-05 1.82505205e-05
 1.81174490e-05 1.79806624e-05 1.78403237e-05 1.76966002e-05
 1.75496630e-05 1.73996874e-05 1.72468520e-05 1.70913390e-05
 1.69333337e-05 1.67730244e-05 1.66106022e-05 1.64462606e-05
 1.62801955e-05 1.61126047e-05 1.59436880e-05 1.57736467e-05
 1.56026834e-05 1.54310019e-05 1.52588068e-05 1.50863032e-05
 1.49136968e-05 1.47411932e-05 1.45689981e-05 1.43973166e-05
 1.42263533e-05 1.40563120e-05 1.38873953e-05 1.37198045e-05
 1.35537394e-05 1.33893978e-05 1.32269756e-05 1.30666663e-05
 1.29086610e-05 1.27531480e-05 1.26003126e-05 1.24503370e-05
 1.23033998e-05 1.21596763e-05 1.20193376e-05 1.18825510e-05
 1.17494795e-05 1.16202818e-05 1.14951117e-05 1.13741185e-05
 1.12574463e-05 1.11452341e-05 1.10376158e-05 1.09347195e-05
 1.08366679e-05 1.07435778e-05 1.06555602e-05 1.05727199e-05
 1.04951557e-05 1.04229600e-05 1.03562188e-05 1.02950117e-05
 1.02394117e-05 1.01894849e-05 1.01452909e-05 1.01068824e-05
 1.00743051e-05 1.00475978e-05 1.00267924e-05 1.00119136e-05
 1.00029793e-05]
Namespace(train_data='../data/meme_retrieval_data/training_set.json', val_data='../data/meme_retrieval_data/validation_set.json', test_data='../data/memecap/meme-cap-main/data/memes-test.json', root='../data/', caption_preprocess='first', image_root='../data/meme_retrieval_data/meme_images', output_dir='./output', model='CLIP_VITL14_336', resume='', epochs=10, warmup_epochs=1, start_epoch=1, batch_size=16, lr=2e-05, lr_start=1e-06, lr_end=1e-05, update_freq=150, wd=0.1, betas=(0.9, 0.98), eps=1e-08, disable_amp=False, print_freq=1, workers=10, distributed=True, world_size=1, rank=0, local_rank=0, dist_url='env://', dist_backend='nccl', seed=0, gpu=0, log_dir='./output/tb_logs')
=> beginning training
Thu Sep 26 20:08:05 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN RTX               Off | 00000000:3D:00.0 Off |                  N/A |
| 41%   32C    P2              60W / 280W |   6991MiB / 24576MiB |     35%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A    597287      C   ...54/.conda/envs/meme_text/bin/python     6988MiB |
+---------------------------------------------------------------------------------------+

/home/bjc154/.conda/envs/meme_text/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch: [1][ 0/10]	Time  82.70 ( 82.70)	Data  81.96 ( 42.46)	Mem (GB)   20.0 (  20.0)	loss 7.69e-05 (7.69e-05)	clip_loss 7.69e-05 (7.69e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [1][ 1/10]	Time  80.27 ( 81.48)	Data  79.57 ( 41.07)	Mem (GB)   20.0 (  20.0)	loss 9.02e-05 (8.35e-05)	clip_loss 9.02e-05 (8.35e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [1][ 2/10]	Time  80.55 ( 81.17)	Data  79.84 ( 40.67)	Mem (GB)   20.0 (  20.0)	loss 1.02e-03 (3.97e-04)	clip_loss 1.02e-03 (3.97e-04)	clip_acc 9.38e+01 (9.79e+01)
Epoch: [1][ 3/10]	Time  80.63 ( 81.04)	Data  79.93 ( 40.48)	Mem (GB)   20.0 (  20.0)	loss 6.31e-05 (3.14e-04)	clip_loss 6.31e-05 (3.14e-04)	clip_acc 1.00e+02 (9.84e+01)
Epoch: [1][ 4/10]	Time  80.65 ( 80.96)	Data  79.95 ( 40.37)	Mem (GB)   20.0 (  20.0)	loss 4.72e-04 (3.45e-04)	clip_loss 4.72e-04 (3.45e-04)	clip_acc 9.38e+01 (9.75e+01)
Epoch: [1][ 5/10]	Time  80.66 ( 80.91)	Data  79.96 ( 40.29)	Mem (GB)   20.0 (  20.0)	loss 3.99e-07 (2.88e-04)	clip_loss 3.99e-07 (2.88e-04)	clip_acc 1.00e+02 (9.79e+01)
Epoch: [1][ 6/10]	Time  80.67 ( 80.88)	Data  79.96 ( 40.24)	Mem (GB)   20.0 (  20.0)	loss 1.63e-05 (2.49e-04)	clip_loss 1.63e-05 (2.49e-04)	clip_acc 1.00e+02 (9.82e+01)
Epoch: [1][ 7/10]	Time  80.68 ( 80.85)	Data  79.98 ( 40.20)	Mem (GB)   20.0 (  20.0)	loss 2.25e-06 (2.18e-04)	clip_loss 2.25e-06 (2.18e-04)	clip_acc 1.00e+02 (9.84e+01)
Epoch: [1][ 8/10]	Time  80.68 ( 80.83)	Data  79.98 ( 40.18)	Mem (GB)   20.0 (  20.0)	loss 2.44e-04 (2.21e-04)	clip_loss 2.44e-04 (2.21e-04)	clip_acc 1.00e+02 (9.86e+01)
Epoch: [1][ 9/10]	Time  80.67 ( 80.82)	Data  79.97 ( 40.15)	Mem (GB)   20.0 (  20.0)	loss 4.59e-05 (2.03e-04)	clip_loss 4.59e-05 (2.03e-04)	clip_acc 1.00e+02 (9.88e+01)
=> encoding captions
88 88
torch.Size([1406, 768])
torch.Size([1406, 768])
{'i2t_r1': 0.8406827880512091, 'i2t_r5': 0.9345661450924608, 'i2t_r10': 0.9615931721194879, 'i2t_r_mean': 0.9122807017543858}
{'t2i_r1': 0.8399715504978663, 't2i_r5': 0.9366998577524893, 't2i_r10': 0.9658605974395448, 't2i_r_mean': 0.9141773352299668}
Validation: [87/88]	Time 55.313 (55.313)	T2I R@1   0.84 (  0.84)	T2I R@5   0.94 (  0.94)	T2I R@10   0.97 (  0.97)	I2T R@1   0.84 (  0.84)	I2T R@5   0.93 (  0.93)	I2T R@10   0.96 (  0.96)
The mean img2text R@K: 0.9122807017543858; The mean text2img R@K: 0.9141773352299668
=> encoding captions
35 35
torch.Size([559, 768])
torch.Size([559, 768])
{'i2t_r1': 0.7656529516994633, 'i2t_r5': 0.9069767441860465, 'i2t_r10': 0.9230769230769231, 'i2t_r_mean': 0.8652355396541443}
{'t2i_r1': 0.7674418604651163, 't2i_r5': 0.8640429338103757, 't2i_r10': 0.8998211091234347, 't2i_r_mean': 0.843768634466309}
Validation: [34/35]	Time 22.757 (22.757)	T2I R@1   0.77 (  0.77)	T2I R@5   0.86 (  0.86)	T2I R@10   0.90 (  0.90)	I2T R@1   0.77 (  0.77)	I2T R@5   0.91 (  0.91)	I2T R@10   0.92 (  0.92)
The mean img2text R@K: 0.8652355396541443; The mean text2img R@K: 0.843768634466309
=> test:  {'r@1': 0.8545020870602267}
=> saving checkpoint
Thu Sep 26 20:24:41 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN RTX               Off | 00000000:3D:00.0 Off |                  N/A |
| 40%   47C    P8              16W / 280W |  10057MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A    597287      C   ...54/.conda/envs/meme_text/bin/python    10054MiB |
+---------------------------------------------------------------------------------------+

/home/bjc154/.conda/envs/meme_text/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch: [2][ 0/10]	Time  80.82 ( 80.82)	Data  80.12 ( 40.27)	Mem (GB)   20.0 (  20.0)	loss 3.51e-07 (3.51e-07)	clip_loss 3.51e-07 (3.51e-07)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [2][ 1/10]	Time  80.61 ( 80.71)	Data  79.90 ( 40.08)	Mem (GB)   20.0 (  20.0)	loss 1.11e-06 (7.33e-07)	clip_loss 1.11e-06 (7.33e-07)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [2][ 2/10]	Time  80.81 ( 80.75)	Data  80.11 ( 40.07)	Mem (GB)   20.0 (  20.0)	loss 2.10e-07 (5.59e-07)	clip_loss 2.10e-07 (5.59e-07)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [2][ 3/10]	Time  80.67 ( 80.73)	Data  79.97 ( 40.03)	Mem (GB)   20.0 (  20.0)	loss 7.03e-07 (5.95e-07)	clip_loss 7.03e-07 (5.95e-07)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [2][ 4/10]	Time  80.67 ( 80.72)	Data  79.96 ( 40.01)	Mem (GB)   20.0 (  20.0)	loss 1.29e-05 (3.06e-06)	clip_loss 1.29e-05 (3.06e-06)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [2][ 5/10]	Time  80.64 ( 80.70)	Data  79.93 ( 40.00)	Mem (GB)   20.0 (  20.0)	loss 2.52e-06 (2.97e-06)	clip_loss 2.52e-06 (2.97e-06)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [2][ 6/10]	Time  80.68 ( 80.70)	Data  79.97 ( 39.99)	Mem (GB)   20.0 (  20.0)	loss 9.06e-08 (2.56e-06)	clip_loss 9.06e-08 (2.56e-06)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [2][ 7/10]	Time  80.64 ( 80.69)	Data  79.94 ( 39.98)	Mem (GB)   20.0 (  20.0)	loss 3.31e-04 (4.36e-05)	clip_loss 3.31e-04 (4.36e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [2][ 8/10]	Time  80.61 ( 80.68)	Data  79.91 ( 39.97)	Mem (GB)   20.0 (  20.0)	loss 1.46e-06 (3.89e-05)	clip_loss 1.46e-06 (3.89e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [2][ 9/10]	Time  80.63 ( 80.68)	Data  79.92 ( 39.96)	Mem (GB)   20.0 (  20.0)	loss 6.10e-06 (3.56e-05)	clip_loss 6.10e-06 (3.56e-05)	clip_acc 1.00e+02 (1.00e+02)
=> encoding captions
88 88
torch.Size([1406, 768])
torch.Size([1406, 768])
{'i2t_r1': 0.8513513513513513, 'i2t_r5': 0.9466571834992887, 'i2t_r10': 0.9672830725462305, 'i2t_r_mean': 0.9217638691322901}
{'t2i_r1': 0.8499288762446657, 't2i_r5': 0.938122332859175, 't2i_r10': 0.957325746799431, 't2i_r_mean': 0.9151256519677573}
Validation: [87/88]	Time 54.968 (54.968)	T2I R@1   0.85 (  0.85)	T2I R@5   0.94 (  0.94)	T2I R@10   0.96 (  0.96)	I2T R@1   0.85 (  0.85)	I2T R@5   0.95 (  0.95)	I2T R@10   0.97 (  0.97)
The mean img2text R@K: 0.9217638691322901; The mean text2img R@K: 0.9151256519677573
=> encoding captions
35 35
torch.Size([559, 768])
torch.Size([559, 768])
{'i2t_r1': 0.7567084078711985, 'i2t_r5': 0.8998211091234347, 'i2t_r10': 0.924865831842576, 'i2t_r_mean': 0.8604651162790699}
{'t2i_r1': 0.7602862254025045, 't2i_r5': 0.8640429338103757, 't2i_r10': 0.8998211091234347, 't2i_r_mean': 0.8413834227787715}
Validation: [34/35]	Time 22.585 (22.585)	T2I R@1   0.76 (  0.76)	T2I R@5   0.86 (  0.86)	T2I R@10   0.90 (  0.90)	I2T R@1   0.76 (  0.76)	I2T R@5   0.90 (  0.90)	I2T R@10   0.92 (  0.92)
The mean img2text R@K: 0.8604651162790699; The mean text2img R@K: 0.8413834227787715
=> test:  {'r@1': 0.8509242695289208}
=> saving checkpoint
Thu Sep 26 20:41:18 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN RTX               Off | 00000000:3D:00.0 Off |                  N/A |
| 41%   46C    P8              16W / 280W |  20817MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A    597287      C   ...54/.conda/envs/meme_text/bin/python    20814MiB |
+---------------------------------------------------------------------------------------+

/home/bjc154/.conda/envs/meme_text/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch: [3][ 0/10]	Time  80.83 ( 80.83)	Data  80.13 ( 40.35)	Mem (GB)   20.0 (  20.0)	loss 4.38e-05 (4.38e-05)	clip_loss 4.38e-05 (4.38e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [3][ 1/10]	Time  80.47 ( 80.65)	Data  79.76 ( 40.09)	Mem (GB)   20.0 (  20.0)	loss 6.62e-05 (5.50e-05)	clip_loss 6.62e-05 (5.50e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [3][ 2/10]	Time  80.51 ( 80.60)	Data  79.81 ( 40.00)	Mem (GB)   20.0 (  20.0)	loss 3.98e-07 (3.68e-05)	clip_loss 3.98e-07 (3.68e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [3][ 3/10]	Time  80.48 ( 80.57)	Data  79.77 ( 39.96)	Mem (GB)   20.0 (  20.0)	loss 5.35e-05 (4.10e-05)	clip_loss 5.35e-05 (4.10e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [3][ 4/10]	Time  80.50 ( 80.56)	Data  79.80 ( 39.94)	Mem (GB)   20.0 (  20.0)	loss 1.08e-07 (3.28e-05)	clip_loss 1.08e-07 (3.28e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [3][ 5/10]	Time  80.44 ( 80.54)	Data  79.74 ( 39.92)	Mem (GB)   20.0 (  20.0)	loss 3.36e-06 (2.79e-05)	clip_loss 3.36e-06 (2.79e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [3][ 6/10]	Time  80.38 ( 80.51)	Data  79.68 ( 39.90)	Mem (GB)   20.0 (  20.0)	loss 4.06e-05 (2.97e-05)	clip_loss 4.06e-05 (2.97e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [3][ 7/10]	Time  80.39 ( 80.50)	Data  79.70 ( 39.89)	Mem (GB)   20.0 (  20.0)	loss 2.11e-08 (2.60e-05)	clip_loss 2.11e-08 (2.60e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [3][ 8/10]	Time  80.39 ( 80.49)	Data  79.70 ( 39.88)	Mem (GB)   20.0 (  20.0)	loss 9.19e-10 (2.31e-05)	clip_loss 9.19e-10 (2.31e-05)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [3][ 9/10]	Time  80.39 ( 80.48)	Data  79.69 ( 39.87)	Mem (GB)   20.0 (  20.0)	loss 9.88e-05 (3.07e-05)	clip_loss 9.88e-05 (3.07e-05)	clip_acc 1.00e+02 (1.00e+02)
=> encoding captions
88 88
torch.Size([1406, 768])
torch.Size([1406, 768])
{'i2t_r1': 0.8549075391180654, 'i2t_r5': 0.9502133712660028, 'i2t_r10': 0.9694167852062588, 'i2t_r_mean': 0.924845898530109}
{'t2i_r1': 0.8556187766714083, 't2i_r5': 0.9374110953058321, 't2i_r10': 0.9644381223328592, 't2i_r_mean': 0.9191559981033666}
Validation: [87/88]	Time 55.021 (55.021)	T2I R@1   0.86 (  0.86)	T2I R@5   0.94 (  0.94)	T2I R@10   0.96 (  0.96)	I2T R@1   0.85 (  0.85)	I2T R@5   0.95 (  0.95)	I2T R@10   0.97 (  0.97)
The mean img2text R@K: 0.924845898530109; The mean text2img R@K: 0.9191559981033666
=> encoding captions
35 35
torch.Size([559, 768])
torch.Size([559, 768])
{'i2t_r1': 0.7602862254025045, 'i2t_r5': 0.8962432915921288, 'i2t_r10': 0.9266547406082289, 'i2t_r_mean': 0.8610614192009541}
{'t2i_r1': 0.774597495527728, 't2i_r5': 0.8711985688729875, 't2i_r10': 0.8980322003577818, 't2i_r_mean': 0.8479427549194991}
Validation: [34/35]	Time 22.665 (22.665)	T2I R@1   0.77 (  0.77)	T2I R@5   0.87 (  0.87)	T2I R@10   0.90 (  0.90)	I2T R@1   0.76 (  0.76)	I2T R@5   0.90 (  0.90)	I2T R@10   0.93 (  0.93)
The mean img2text R@K: 0.8610614192009541; The mean text2img R@K: 0.8479427549194991
=> test:  {'r@1': 0.8545020870602267}
=> saving checkpoint
Thu Sep 26 20:57:54 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA TITAN RTX               Off | 00000000:3D:00.0 Off |                  N/A |
| 40%   46C    P8              24W / 280W |  20817MiB / 24576MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|    0   N/A  N/A    597287      C   ...54/.conda/envs/meme_text/bin/python    20814MiB |
+---------------------------------------------------------------------------------------+

/home/bjc154/.conda/envs/meme_text/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Epoch: [4][ 0/10]	Time  80.56 ( 80.56)	Data  79.86 ( 40.14)	Mem (GB)   20.0 (  20.0)	loss 8.60e-07 (8.60e-07)	clip_loss 8.60e-07 (8.60e-07)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [4][ 1/10]	Time  80.36 ( 80.46)	Data  79.66 ( 39.96)	Mem (GB)   20.0 (  20.0)	loss 5.69e-08 (4.58e-07)	clip_loss 5.69e-08 (4.58e-07)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [4][ 2/10]	Time  80.41 ( 80.44)	Data  79.71 ( 39.91)	Mem (GB)   20.0 (  20.0)	loss 1.86e-05 (6.50e-06)	clip_loss 1.86e-05 (6.50e-06)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [4][ 3/10]	Time  80.44 ( 80.44)	Data  79.74 ( 39.88)	Mem (GB)   20.0 (  20.0)	loss 3.31e-08 (4.89e-06)	clip_loss 3.31e-08 (4.89e-06)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [4][ 4/10]	Time  80.44 ( 80.44)	Data  79.74 ( 39.87)	Mem (GB)   20.0 (  20.0)	loss 7.71e-07 (4.06e-06)	clip_loss 7.71e-07 (4.06e-06)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [4][ 5/10]	Time  80.41 ( 80.44)	Data  79.71 ( 39.86)	Mem (GB)   20.0 (  20.0)	loss 1.99e-05 (6.70e-06)	clip_loss 1.99e-05 (6.70e-06)	clip_acc 1.00e+02 (1.00e+02)
Epoch: [4][ 6/10]	Time  80.42 ( 80.43)	Data  79.72 ( 39.85)	Mem (GB)   20.0 (  20.0)	loss 1.34e-04 (2.48e-05)	clip_loss 1.34e-04 (2.48e-05)	clip_acc 1.00e+02 (1.00e+02)
slurmstepd: error: *** JOB 3752 ON hendrixgpu19fl CANCELLED AT 2024-09-26T21:07:40 DUE TO TIME LIMIT ***
