{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install evaluate\n",
    "# ! pip install bert_score\n",
    "# ! pip install sacrebleu\n",
    "# ! pip install nltk\n",
    "# ! pip install rouge_score\n",
    "# ! pip install torchmetrics\n",
    "# # for BLEURT refer to https://github.com/google-research/bleurt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiling/anaconda3/envs/llava/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-08-06 10:14:09.242261: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-06 10:14:09.250734: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-08-06 10:14:09.261284: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-08-06 10:14:09.264388: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-06 10:14:09.272475: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-06 10:14:09.832473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(464,\n",
       " \"- The meme humorously suggests that a wife, after losing her memory, fell in love with and decided to remarry her own husband, indicating his unchanging worth and likeability as a partner, paralleled by the character's proud declaration of worthiness regarding his hammer.\",\n",
       " 'memes_d079np.png')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pprint \n",
    "import numpy as np\n",
    "from evaluate import load\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "img_prompt_respond_file = '../data/memecap/filtered_meme_configs_5_attributes_memecap.json'\n",
    "# Load predictions\n",
    "predictions = []\n",
    "with open(img_prompt_respond_file, 'r', encoding='utf-8') as json_file:\n",
    "    predictions = json.load(json_file)\n",
    "len(predictions), predictions[0]['meaning of the meme'], predictions[0]['image_dir'].split('/')[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load gtound truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 1567, 1567, 464, 464)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = []\n",
    "with open('../data/memecap/meme-cap-main/data/memes-test.json', 'r', encoding='utf-8') as json_file:\n",
    "    gt = json.load(json_file)\n",
    "len(gt), gt[0]['meme_captions'], gt[0]['img_fname']\n",
    "# concatenate all the references from the ground truth.\n",
    "memecap_predictions_concatenated = []\n",
    "memecap_processed_gt_concatenated = []\n",
    "# copy the predictions to match the number of references\n",
    "memecap_predictions_extended = []\n",
    "memecap_processed_gt_extended = []\n",
    "# Do nothing. One-prediction to multi-reference\n",
    "memecap_predictions_multi_ref = []\n",
    "memecap_processed_gt_multi_ref = []\n",
    "\n",
    "for idx, meme_conf in enumerate(predictions):\n",
    "    for meme in gt:\n",
    "        if meme_conf['image_dir'].split('/')[-1] == meme['img_fname']:\n",
    "            memecap_predictions_concatenated.append(meme_conf['meaning of the meme'])\n",
    "            memecap_processed_gt_concatenated.append(''.join(meme['meme_captions']))\n",
    "            \n",
    "            memecap_predictions_extended += [meme_conf['meaning of the meme']] * len(meme['meme_captions'])\n",
    "            memecap_processed_gt_extended += meme['meme_captions']\n",
    "\n",
    "            memecap_predictions_multi_ref.append(meme_conf['meaning of the meme'])\n",
    "            memecap_processed_gt_multi_ref.append(meme['meme_captions'])\n",
    "len(memecap_processed_gt_concatenated), len(memecap_processed_gt_extended), len(memecap_predictions_extended), len(memecap_predictions_multi_ref), len(memecap_processed_gt_multi_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLEURT\n",
    "## Github repo\n",
    "https://github.com/google-research/bleurt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_the_best_matches(target_scores, sample_size, multi_ref): \n",
    "    # Calculate the score for the best matches \n",
    "    restored_scores = []\n",
    "    last_idx = 0\n",
    "    for i in range(sample_size):\n",
    "        restored_scores.append(target_scores[last_idx : last_idx + len(multi_ref[i])])\n",
    "        last_idx += len(multi_ref[i]) \n",
    "    # print(restored_scores)\n",
    "    maximized = [ max(ite) for ite in restored_scores]\n",
    "    print('The average score for the best matches:', np.mean(maximized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /home/shiling/git/bleurt/BLEURT-20.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /home/shiling/git/bleurt/BLEURT-20.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:BLEURT-20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:BLEURT-20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... sp_model:sent_piece\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... sp_model:sent_piece\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... dynamic_seq_length:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... dynamic_seq_length:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load model: /home/shiling/git/bleurt/BLEURT-20/sent_piece.model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load model: /home/shiling/git/bleurt/BLEURT-20/sent_piece.model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SentencePiece tokenizer created.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SentencePiece tokenizer created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended version: 0.47095482013335105\n",
      "The average score for the best matches: 0.5254725490793072\n",
      "Concatenated version: 0.47439709543411074\n"
     ]
    }
   ],
   "source": [
    "from bleurt import score\n",
    "\n",
    "checkpoint = \"/home/shiling/git/bleurt/BLEURT-20\"\n",
    "# references = [\"This is a test.\", \"This is a test.\"]\n",
    "# candidates = [\"This is a test.\", \"This is the test.\"]\n",
    "# [0.9881654977798462, 0.7926645278930664]\n",
    "\n",
    "scorer = score.BleurtScorer(checkpoint)\n",
    "# Extended predictions\n",
    "scores = scorer.score(references=memecap_processed_gt_extended, candidates=memecap_predictions_extended)\n",
    "print('Extended version:', np.mean(scores))\n",
    "\n",
    "calculate_the_best_matches(scores, len(memecap_predictions_multi_ref), memecap_processed_gt_multi_ref)\n",
    "\n",
    "# Concatenated references\n",
    "scores = scorer.score(references=memecap_processed_gt_concatenated, candidates=memecap_predictions_concatenated)\n",
    "print('Concatenated version:', np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface interface\n",
    "https://huggingface.co/spaces/evaluate-metric/bleurt/blob/main/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:evaluate_modules.metrics.evaluate-metric--bleurt.98e148b2f8c4a88aba5037e4e0e90c9fd9ec35dc37a054ded8cfef0fa801ffab.bleurt:Using default BLEURT-Base checkpoint for sequence maximum length 128. You can use a bigger model for better results with e.g.: evaluate.load('bleurt', 'bleurt-large-512').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /home/shiling/.cache/huggingface/metrics/bleurt/default/downloads/extracted/13db1fc9d295585583f8a5538b232c82f61e73738f37827f3c4fc14396e60785/bleurt-base-128.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /home/shiling/.cache/huggingface/metrics/bleurt/default/downloads/extracted/13db1fc9d295585583f8a5538b232c82f61e73738f37827f3c4fc14396e60785/bleurt-base-128.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Config file found, reading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Will load checkpoint bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loads full paths and checks that files exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... name:bert_custom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... vocab_file:vocab.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... bert_config_file:bert_config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... do_lower_case:True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:... max_seq_length:128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating BLEURT scorer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating WordPiece tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:WordPiece tokenizer instantiated.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Creating Eager Mode predictor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example: 0.8682224154472351\n",
      "Extended version: -0.6088926426224748\n",
      "Concatenated version: -0.5713593499445967\n"
     ]
    }
   ],
   "source": [
    "bleurt_scorer = load(\"bleurt\", module_type=\"metric\", checkpoint=\"BLEURT-20\")\n",
    "references = [\"This is a test.\", \"This is a test.\"]\n",
    "candidates = [\"This is a test.\", \"This is the test.\"]\n",
    "scores = bleurt_scorer.compute(predictions=candidates, references=references)\n",
    "print('Example:', np.mean(scores['scores']))\n",
    "# Extended predictions\n",
    "scores = bleurt_scorer.compute(predictions=memecap_predictions_extended, references=memecap_processed_gt_extended)\n",
    "print('Extended version:', np.mean(scores['scores']))\n",
    "\n",
    "# Concatenated references\n",
    "scores = bleurt_scorer.compute(predictions=memecap_predictions_concatenated, references=memecap_processed_gt_concatenated)\n",
    "print('Concatenated version:', np.mean(scores['scores']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERTscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertscore = load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['precision', 'recall', 'f1', 'hashcode'])\n",
      "0.8596986218782923 0.8784849302891948 0.8689020508858681\n",
      "The average score for the best matches: 0.879493215859964\n",
      "0.8675926138871702 0.8604510788773668 0.8639449427097008\n",
      "0.8698499315771563 0.8925056580839485 0.879493215859964\n"
     ]
    }
   ],
   "source": [
    "# Extended predictions\n",
    "results = bertscore.compute(predictions=memecap_predictions_extended, references=memecap_processed_gt_extended, lang=\"en\")\n",
    "print(results.keys())\n",
    "print(np.mean(results['precision']), np.mean(results['recall']), np.mean(results['f1']))\n",
    "\n",
    "calculate_the_best_matches(results['f1'], len(memecap_predictions_multi_ref), memecap_processed_gt_multi_ref)\n",
    "\n",
    "# Concatenated references\n",
    "results = bertscore.compute(predictions=memecap_predictions_concatenated, references=memecap_processed_gt_concatenated, lang=\"en\")\n",
    "print(np.mean(results['precision']), np.mean(results['recall']), np.mean(results['f1']))\n",
    "\n",
    "# One-prediction to multi-reference\n",
    "results = bertscore.compute(predictions=memecap_predictions_multi_ref, references=memecap_processed_gt_multi_ref, lang=\"en\")\n",
    "print(np.mean(results['precision']), np.mean(results['recall']), np.mean(results['f1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChrF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Huggingface interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = [\"The relationship between cats and dogs is not exactly friendly.\", \"a good bookshop is just a genteel black hole that knows how to read.\"]\n",
    "# reference = [[\"The relationship between dogs and cats is not exactly friendly.\", ], [\"A good bookshop is just a genteel Black Hole that knows how to read.\"]]\n",
    "chrf = load(\"chrf\")\n",
    "\n",
    "# {'score': 84.64214891738334, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
    "\n",
    "# Extended predictions\n",
    "results = chrf.compute(predictions=memecap_predictions_extended, references=memecap_processed_gt_extended)\n",
    "print(results)\n",
    "# Concatenated predictions\n",
    "results = chrf.compute(predictions=memecap_predictions_concatenated, references=memecap_processed_gt_concatenated)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # one prediction to multiple references -- Huggingface\n",
    "# # ValueError: ChrF, as implemented by sacrebleu, requires the same number of references for each prediction\n",
    "# results = chrf.compute(predictions=memecap_predictions_multi_ref, references=memecap_processed_gt_multi_ref)\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torchmetrics interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2883)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one prediction and multiple references\n",
    "from torchmetrics.text import CHRFScore\n",
    "# preds = ['the cat is on the mat']\n",
    "# target = [['there is a cat on the mat', 'a cat is on the mat']]\n",
    "chrf = CHRFScore()\n",
    "chrf(memecap_predictions_multi_ref, memecap_processed_gt_multi_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2450)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extended predictions\n",
    "chrf(memecap_predictions_extended, memecap_processed_gt_extended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2077)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenated references\n",
    "chrf(memecap_predictions_concatenated, memecap_processed_gt_concatenated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROUGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge = load('rouge')\n",
    "predictions = [\"hello there\", \"general kenobi\"]\n",
    "references = [\"hello there\", \"general kenobi\"]\n",
    "\n",
    "# {'rouge1': 1.0, 'rouge2': 1.0, 'rougeL': 1.0, 'rougeLsum': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.21358079742963504, 'rouge2': 0.0416616902071557, 'rougeL': 0.17265236393343997, 'rougeLsum': 0.1726669393742032}\n"
     ]
    }
   ],
   "source": [
    "# Extended predictions\n",
    "results = rouge.compute(predictions=memecap_predictions_extended,\n",
    "                        references=memecap_processed_gt_extended)\n",
    "print(results)\n",
    "\n",
    "# Concatenated references\n",
    "results = rouge.compute(predictions=memecap_predictions_concatenated,\n",
    "                        references=memecap_processed_gt_concatenated)\n",
    "print(results)\n",
    "\n",
    "# one prediction VS multiple references\n",
    "results = rouge.compute(predictions=memecap_predictions_multi_ref, \n",
    "                        references=memecap_processed_gt_multi_ref)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = [\"hello there general kenobi\", \"foo bar foobar\"]\n",
    "# references = [\n",
    "#     [\"hello there general kenobi\", \"hello there !\"],\n",
    "#     [\"foo bar foobar\"]\n",
    "# ]\n",
    "bleu =load(\"bleu\")\n",
    "\n",
    "# {'bleu': 1.0, 'precisions': [1.0, 1.0, 1.0, 1.0], 'brevity_penalty': 1.0, 'length_ratio': 1.1666666666666667, 'translation_length': 7, 'reference_length': 6}\n",
    "\n",
    "# Extended predictions\n",
    "bleu =load(\"bleu\")\n",
    "results = bleu.compute(predictions=memecap_predictions_extended, \n",
    "                       references=memecap_processed_gt_extended, max_order=4)\n",
    "print(results)\n",
    "\n",
    "\n",
    "# Concatenated references\n",
    "results = bleu.compute(predictions=memecap_predictions_concatenated, \n",
    "                       references=memecap_processed_gt_concatenated)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bleu': 0.03673635280307039, 'precisions': [0.29231815091774305, 0.06801552459120698, 0.016127974824624663, 0.005679897220907431], 'brevity_penalty': 1.0, 'length_ratio': 2.7467323035138347, 'translation_length': 16181, 'reference_length': 5891}\n"
     ]
    }
   ],
   "source": [
    "# one prediction VS multiple references\n",
    "from nltk.tokenize import word_tokenize\n",
    "results = bleu.compute(predictions=memecap_predictions_multi_ref, \n",
    "                       references=memecap_processed_gt_multi_ref, tokenizer=word_tokenize)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Justify that the sentence length has an influence on the final score for n-gram based metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    [\"The meme poster is celebrating the husband's success in making his wife fall in love with him again after she lost her memory.\",\n",
    "    \"The husband feels validated and proud that he was able to win his wife's heart for the second time.\",\n",
    "    \"The meme poster is emphasizing the husband's worthiness and capability of rekindling the love with his wife despite the challenges.\" ],\n",
    "    [\"The meme poster is suggesting that The Simpsons once again predicted a real-life event involving Donald Trump and Greta Thunberg.\",\n",
    "    \"Meme creator draws a parallel between Lisa Simpson's character and Greta Thunberg, emphasizing their roles as outspoken young activists.\",\n",
    "    \"The poster is highlighting the uncanny resemblance between scenes from The Simpsons and actual events, suggesting the show has a history of accurately predicting the future.\"]\n",
    "]\n",
    "\n",
    "ground_truth = [[\n",
    "    'Husband feels great after having their wife fall in love with him again after getting amnesia.',\n",
    "    'The meme poster feels happy for the person who make his wife remember their love even after she forgot all.',\n",
    "    'meme poster is conveying they feel like thor when a woman says to marrying them '], [\n",
    "    \"The Simpsons was correct about it's use of Trump and Greta Thurnberg. \",\n",
    "    'The Simpsons is able to predict so many real life situation including Trump and Greta Thurnburg.'\n",
    "    ]]\n",
    "# concatnate all predictions and references of the same sample\n",
    "memecap_predictions_fully_concatenated = []\n",
    "memecap_processed_gt_fully_concatenated = []\n",
    "\n",
    "# Flatten pridictions\n",
    "new_predictions = []\n",
    "new_gt = []\n",
    "for idx, ite in enumerate(predictions):\n",
    "    memecap_predictions_fully_concatenated.append(\" \".join(ite))\n",
    "    memecap_processed_gt_fully_concatenated.append(\" \".join(ground_truth[idx]))\n",
    "    for predict in ite:\n",
    "        new_predictions.append(predict)\n",
    "        new_gt.append(ground_truth[idx])\n",
    "predictions = new_predictions\n",
    "ground_truth = new_gt\n",
    "len(predictions), len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions = [\"- The meme humorously suggests that a wife, after losing her memory, fell in love with and decided to remarry her own husband, indicating his unchanging worth and likeability as a partner, paralleled by the character's proud declaration of worthiness regarding his hammer.\", \n",
    "#                'The meme humorously suggests that the TV show \"The Simpsons\" predicted real-life events involving Greta Thunberg and Donald Trump.']\n",
    "\n",
    "# ground_truth = [[\n",
    "#     'Husband feels great after having their wife fall in love with him again after getting amnesia.',\n",
    "#     'The meme poster feels happy for the person who make his wife remember their love even after she forgot all.',\n",
    "#     'meme poster is conveying they feel like thor when a woman says to marrying them '], [\n",
    "#     \"The Simpsons was correct about it's use of Trump and Greta Thurnberg. \",\n",
    "#     'The Simpsons is able to predict so many real life situation including Trump and Greta Thurnburg.'\n",
    "#     ]]\n",
    "\n",
    "# len(predictions[0]), len(predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 15, 15, 6, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt = ground_truth\n",
    "\n",
    "# concatenate all the references from the ground truth.\n",
    "memecap_predictions_concatenated = []\n",
    "memecap_processed_gt_concatenated = []\n",
    "# copy the predictions to match the number of references\n",
    "memecap_predictions_extended = []\n",
    "memecap_processed_gt_extended = []\n",
    "# Do nothing. One-prediction to multi-reference\n",
    "memecap_predictions_multi_ref = predictions\n",
    "memecap_processed_gt_multi_ref = gt\n",
    "\n",
    "for idx, predic in enumerate(predictions):\n",
    "    memecap_predictions_concatenated.append(predic)\n",
    "    memecap_processed_gt_concatenated.append(''.join(gt[idx]))\n",
    "    \n",
    "    memecap_predictions_extended += [predic] * len(gt[idx])\n",
    "    memecap_processed_gt_extended += gt[idx]\n",
    "\n",
    "len(memecap_processed_gt_concatenated), len(memecap_processed_gt_extended), len(memecap_predictions_extended), len(memecap_predictions_multi_ref), len(memecap_processed_gt_multi_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reading checkpoint /home/shiling/git/bleurt/BLEURT-20.\n",
      "INFO:tensorflow:Config file found, reading.\n",
      "INFO:tensorflow:Will load checkpoint BLEURT-20\n",
      "INFO:tensorflow:Loads full paths and checks that files exists.\n",
      "INFO:tensorflow:... name:BLEURT-20\n",
      "INFO:tensorflow:... bert_config_file:bert_config.json\n",
      "INFO:tensorflow:... max_seq_length:512\n",
      "INFO:tensorflow:... vocab_file:None\n",
      "INFO:tensorflow:... do_lower_case:None\n",
      "INFO:tensorflow:... sp_model:sent_piece\n",
      "INFO:tensorflow:... dynamic_seq_length:True\n",
      "INFO:tensorflow:Creating BLEURT scorer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Creating SentencePiece tokenizer.\n",
      "INFO:tensorflow:Will load model: /home/shiling/git/bleurt/BLEURT-20/sent_piece.model.\n",
      "INFO:tensorflow:SentencePiece tokenizer created.\n",
      "INFO:tensorflow:Creating Eager Mode predictor.\n",
      "INFO:tensorflow:Loading model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722932062.079906    5332 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722932062.080568    5332 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722932062.080649    5332 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722932062.081116    5332 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722932062.081192    5332 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722932062.081268    5332 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722932062.142592    5332 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722932062.142720    5332 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722932062.142796    5332 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-06 10:14:22.142857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9909 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:BLEURT initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended version: [0.5869571566581726, 0.6647629141807556, 0.4271870255470276, 0.5381008386611938, 0.5013132691383362, 0.3244766592979431, 0.4955701231956482, 0.5975973606109619, 0.4423678517341614, 0.536298394203186, 0.6327395439147949, 0.3608573079109192, 0.36088889837265015, 0.294441819190979, 0.38294482231140137]\n",
      "Mean of the extended version: 0.47643359899520876\n",
      "[[0.5869571566581726, 0.6647629141807556, 0.4271870255470276], [0.5381008386611938, 0.5013132691383362, 0.3244766592979431], [0.4955701231956482, 0.5975973606109619, 0.4423678517341614], [0.536298394203186, 0.6327395439147949], [0.3608573079109192, 0.36088889837265015], [0.294441819190979, 0.38294482231140137]]\n",
      "The average score for the best matches: 0.529505729675293\n",
      "Concatenated version: [0.5480329394340515, 0.48804110288619995, 0.5097494721412659, 0.6075407862663269, 0.41089391708374023, 0.5098664164543152]\n",
      "Mean of the concatenated version: 0.5123541057109833\n",
      "Fully concatenated version: [0.5299772620201111, 0.5654913187026978]\n",
      "Mean of the fully concatenated version: 0.5477342903614044\n"
     ]
    }
   ],
   "source": [
    "## BLEURT\n",
    "from bleurt import score\n",
    "checkpoint = \"/home/shiling/git/bleurt/BLEURT-20\"\n",
    "bleurt_scorer = score.BleurtScorer(checkpoint)\n",
    "\n",
    "# Extended predictions\n",
    "scores = bleurt_scorer.score(references=memecap_processed_gt_extended, candidates=memecap_predictions_extended)\n",
    "print('Extended version:', scores)\n",
    "print('Mean of the extended version:', np.mean(scores))\n",
    "\n",
    "# Calculate the score for the best matches \n",
    "restored_scores = []\n",
    "last_idx = 0\n",
    "for i in range(len(predictions)):\n",
    "    restored_scores.append(scores[last_idx : last_idx + len(gt[i])])\n",
    "    last_idx += len(gt[i])\n",
    "print(restored_scores)\n",
    "maximized = [ max(ite) for ite in restored_scores]\n",
    "print('The average score for the best matches:', np.mean(maximized))\n",
    "\n",
    "# Concatenated references\n",
    "scores = bleurt_scorer.score(references=memecap_processed_gt_concatenated, candidates=memecap_predictions_concatenated)\n",
    "print('Concatenated version:', scores)\n",
    "print('Mean of the concatenated version:', np.mean(scores))\n",
    "\n",
    "# Fully concatenated references\n",
    "scores = bleurt_scorer.score(references=memecap_processed_gt_fully_concatenated, candidates=memecap_predictions_fully_concatenated)\n",
    "print('Fully concatenated version:', scores)\n",
    "print('Mean of the fully concatenated version:', np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2066854990583804"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([0.13559322033898305, 0.2777777777777778])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiling/anaconda3/envs/llava/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended version: 0.8819923917452495 0.8825521032015483 0.8822169462839763\n",
      "Concatenated version: 0.886967142422994 0.866187334060669 0.8764044344425201\n",
      "Fully concatenated version: 0.8775137364864349 0.8948593735694885 0.8860620558261871\n",
      "Multi-ref version: 0.8945286969343821 0.8968304892381033 0.8953786293665568\n"
     ]
    }
   ],
   "source": [
    "## BERTscore\n",
    "bertscore = load(\"bertscore\")\n",
    "# Extended predictions\n",
    "results = bertscore.compute(predictions=memecap_predictions_extended, references=memecap_processed_gt_extended, lang=\"en\")\n",
    "print('Extended version:', np.mean(results['precision']), np.mean(results['recall']), np.mean(results['f1']))\n",
    "\n",
    "# Concatenated references\n",
    "results = bertscore.compute(predictions=memecap_predictions_concatenated, references=memecap_processed_gt_concatenated, lang=\"en\")\n",
    "print('Concatenated version:', np.mean(results['precision']), np.mean(results['recall']), np.mean(results['f1']))\n",
    "\n",
    "\n",
    "# Fully concatenated references\n",
    "results = bertscore.compute(predictions=memecap_predictions_fully_concatenated, references=memecap_processed_gt_fully_concatenated, lang=\"en\")\n",
    "print('Fully concatenated version:', np.mean(results['precision']), np.mean(results['recall']), np.mean(results['f1']))\n",
    "\n",
    "# One-prediction to multi-reference\n",
    "results = bertscore.compute(predictions=memecap_predictions_multi_ref, references=memecap_processed_gt_multi_ref, lang=\"en\")\n",
    "print('Multi-ref version:', np.mean(results['precision']), np.mean(results['recall']), np.mean(results['f1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extended version: {'score': 33.32482804288148, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "Concatenated version: {'score': 25.869841671634354, 'char_order': 6, 'word_order': 0, 'beta': 2}\n",
      "Fully concatenated version: {'score': 42.40475235853734, 'char_order': 6, 'word_order': 0, 'beta': 2}\n"
     ]
    }
   ],
   "source": [
    "## CHrF\n",
    "chrf = load(\"chrf\")\n",
    "# Extended predictions\n",
    "results = chrf.compute(predictions=memecap_predictions_extended, references=memecap_processed_gt_extended)\n",
    "print('Extended version:', results)\n",
    "# Concatenated references\n",
    "results = chrf.compute(predictions=memecap_predictions_concatenated, references=memecap_processed_gt_concatenated)\n",
    "print('Concatenated version:', results)\n",
    "# Fully concatenated references\n",
    "results = chrf.compute(predictions=memecap_predictions_fully_concatenated, references=memecap_processed_gt_fully_concatenated)\n",
    "print('Fully concatenated version:', results)\n",
    "\n",
    "# ## CHrF\n",
    "# chrf = load(\"chrf\")\n",
    "# print(\"sample 1:\")\n",
    "# # Extended predictions\n",
    "# results = chrf.compute(predictions=memecap_predictions_extended[:2], references=memecap_processed_gt_extended[:2])\n",
    "# print('Extended version:', results)\n",
    "# # Concatenated references\n",
    "# results = chrf.compute(predictions=[memecap_predictions_concatenated[0]], references=[memecap_processed_gt_concatenated[0]])\n",
    "# print('Concatenated version:', results)\n",
    "\n",
    "# print(\"sample 2:\")\n",
    "# # Extended predictions\n",
    "# results = chrf.compute(predictions=memecap_predictions_extended[2:], references=memecap_processed_gt_extended[2:])\n",
    "# print('Extended version:', results)\n",
    "# # Concatenated references\n",
    "# results = chrf.compute(predictions=[memecap_predictions_concatenated[1]], references=[memecap_processed_gt_concatenated[1]])\n",
    "# print('Concatenated version:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample 1:\n",
      "Extended version: {'rouge1': 0.24159525176741817, 'rouge2': 0.11965887014686075, 'rougeL': 0.2192834451873189, 'rougeLsum': 0.22125348747299967}\n",
      "Concatenated version: {'rouge1': 0.2717378924823593, 'rouge2': 0.1294849381423825, 'rougeL': 0.19014496793168825, 'rougeLsum': 0.19061430632859208}\n",
      "Fully concatenated version: {'rouge1': 0.34410919540229884, 'rouge2': 0.1954087346024636, 'rougeL': 0.22126436781609193, 'rougeLsum': 0.22126436781609193}\n",
      "Multi-ref version: {'rouge1': 0.3184737056688276, 'rouge2': 0.15808828287605878, 'rougeL': 0.27187631090070113, 'rougeLsum': 0.2736665306787258}\n"
     ]
    }
   ],
   "source": [
    "## ROUGE\n",
    "rouge = load('rouge')\n",
    "print(\"sample 1:\")\n",
    "# Extended predictions\n",
    "results = rouge.compute(predictions=memecap_predictions_extended,\n",
    "                        references=memecap_processed_gt_extended)\n",
    "print('Extended version:', results)\n",
    "\n",
    "# Concatenated reference\n",
    "results = rouge.compute(predictions=memecap_predictions_concatenated,\n",
    "                        references=memecap_processed_gt_concatenated)\n",
    "print('Concatenated version:', results)\n",
    "\n",
    "# Fully concatenated reference\n",
    "results = rouge.compute(predictions=memecap_predictions_fully_concatenated,\n",
    "                        references=memecap_processed_gt_fully_concatenated)\n",
    "print('Fully concatenated version:', results)\n",
    "\n",
    "# One-prediction to multi-reference\n",
    "results = rouge.compute(predictions=memecap_predictions_multi_ref,\n",
    "                        references=memecap_processed_gt_multi_ref)\n",
    "print('Multi-ref version:', results)\n",
    "\n",
    "# ## ROUGE\n",
    "# rouge = load('rouge')\n",
    "# print(\"sample 1:\")\n",
    "# # Extended predictions\n",
    "# results = rouge.compute(predictions=memecap_predictions_extended[:2],\n",
    "#                         references=memecap_processed_gt_extended[:2])\n",
    "# print('Extended version:', results)\n",
    "\n",
    "# # Concatenated reference\n",
    "# results = rouge.compute(predictions=[memecap_predictions_concatenated[0]],\n",
    "#                         references=[memecap_processed_gt_concatenated[0]])\n",
    "# print('Concatenated version:', results)\n",
    "\n",
    "# # One-prediction to multi-reference\n",
    "# results = rouge.compute(predictions=[memecap_predictions_multi_ref[0]],\n",
    "#                         references=[memecap_processed_gt_multi_ref[0]])\n",
    "# print('Multi-ref version:', results)\n",
    "\n",
    "# print(\"sample 2:\")\n",
    "# # Extended predictions\n",
    "# results = rouge.compute(predictions=memecap_predictions_extended[2:],\n",
    "#                         references=memecap_processed_gt_extended[2:])\n",
    "# print('Extended version:', results)\n",
    "\n",
    "# # Concatenated reference\n",
    "# results = rouge.compute(predictions=[memecap_predictions_concatenated[1]],\n",
    "#                         references=[memecap_processed_gt_concatenated[1]])\n",
    "# print('Concatenated version:', results)\n",
    "\n",
    "# # One-prediction to multi-reference\n",
    "# results = rouge.compute(predictions=[memecap_predictions_multi_ref[1]],\n",
    "#                         references=[memecap_processed_gt_multi_ref[1]])\n",
    "# print('Multi-ref version:', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1\n",
      "Extended version: {'bleu': 0.06142713874076677, 'precisions': [0.22388059701492538, 0.09375, 0.03934426229508197, 0.017241379310344827], 'brevity_penalty': 1.0, 'length_ratio': 1.3453815261044177, 'translation_length': 335, 'reference_length': 249}\n",
      "Concatenated version: {'bleu': 0.054440737502768774, 'precisions': [0.37777777777777777, 0.17829457364341086, 0.08943089430894309, 0.042735042735042736], 'brevity_penalty': 0.4297960674895162, 'length_ratio': 0.5421686746987951, 'translation_length': 135, 'reference_length': 249}\n",
      "Fully concatenated version: {'bleu': 0.11133493590639636, 'precisions': [0.2740740740740741, 0.15789473684210525, 0.07633587786259542, 0.046511627906976744], 'brevity_penalty': 1.0, 'length_ratio': 1.6265060240963856, 'translation_length': 135, 'reference_length': 83}\n",
      "Multi-ref version: {'bleu': 0.1254059199425261, 'precisions': [0.362962962962963, 0.17829457364341086, 0.08943089430894309, 0.042735042735042736], 'brevity_penalty': 1.0, 'length_ratio': 1.6071428571428572, 'translation_length': 135, 'reference_length': 84}\n"
     ]
    }
   ],
   "source": [
    "# BLEU\n",
    "bleu =load(\"bleu\")\n",
    "print('Sample 1')\n",
    "# Extended predictions\n",
    "results = bleu.compute(predictions=memecap_predictions_extended, \n",
    "                       references=memecap_processed_gt_extended, max_order=4)\n",
    "print('Extended version:', results)\n",
    "\n",
    "# Concatenated reference\n",
    "results = bleu.compute(predictions=memecap_predictions_concatenated, \n",
    "                       references=memecap_processed_gt_concatenated, max_order=4)\n",
    "print('Concatenated version:', results)\n",
    "\n",
    "# Fully concatenated reference\n",
    "results = bleu.compute(predictions=memecap_predictions_fully_concatenated, \n",
    "                       references=memecap_processed_gt_fully_concatenated, max_order=4)\n",
    "print('Fully concatenated version:', results)\n",
    "\n",
    "# One-prediction to multi-reference\n",
    "results = bleu.compute(predictions=memecap_predictions_multi_ref, \n",
    "                       references=memecap_processed_gt_multi_ref, max_order=4)\n",
    "print('Multi-ref version:', results)\n",
    "\n",
    "# ## BLEU\n",
    "# bleu =load(\"bleu\")\n",
    "# print('Sample 1')\n",
    "# # Extended predictions\n",
    "# results = bleu.compute(predictions=memecap_predictions_extended[:2], \n",
    "#                        references=memecap_processed_gt_extended[:2], max_order=4)\n",
    "# print('Extended version:', results)\n",
    "\n",
    "# # Concatenated reference\n",
    "# results = bleu.compute(predictions=[memecap_predictions_concatenated[0]], \n",
    "#                        references=[memecap_processed_gt_concatenated[0]], max_order=4)\n",
    "# print('Concatenated version:', results)\n",
    "\n",
    "# # One-prediction to multi-reference\n",
    "# results = bleu.compute(predictions=[memecap_predictions_multi_ref[0]], \n",
    "#                        references=[memecap_processed_gt_multi_ref[0]], max_order=4)\n",
    "# print('Multi-ref version:', results)\n",
    "\n",
    "# print('Sample 2')\n",
    "# # Extended predictions\n",
    "# results = bleu.compute(predictions=memecap_predictions_extended[2:], \n",
    "#                        references=memecap_processed_gt_extended[2:], max_order=4)\n",
    "# print('Extended version:', results)\n",
    "\n",
    "# # Concatenated reference\n",
    "# results = bleu.compute(predictions=[memecap_predictions_concatenated[1]], \n",
    "#                        references=[memecap_processed_gt_concatenated[1]], max_order=4)\n",
    "# print('Concatenated version:', results)\n",
    "\n",
    "# # One-prediction to multi-reference\n",
    "# results = bleu.compute(predictions=[memecap_predictions_multi_ref[1]], \n",
    "#                        references=[memecap_processed_gt_multi_ref[1]], max_order=4)\n",
    "# print('Multi-ref version:', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
