{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load annotated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# dataset_name = 'meme_retrieval_data'\n",
    "# dataset_name = 'figmemes'\n",
    "# dataset_name = 'figmemes_cot'\n",
    "dataset_name = 'figmemes_cot_few_shot'\n",
    "# dataset_name = 'memecap'\n",
    "\n",
    "img_prompt_respond_file = ''\n",
    "gt_data_file = ''\n",
    "if dataset_name == 'meme_retrieval_data':\n",
    "    img_prompt_respond_file = '../data/meme_retrieval_data/filtered_meme_configs_5_attributes_meme_retri.json'\n",
    "elif dataset_name == 'figmemes':\n",
    "    img_prompt_respond_file = '../data/figmemes/filtered_meme_configs_figmemes_multi_labels.json'\n",
    "    gt_data_file = '../data/figmemes/figmemes_annotations.tsv'\n",
    "elif dataset_name == 'figmemes_cot':\n",
    "    img_prompt_respond_file = '../data/figmemes/filtered_meme_configs_figmemes_cot.json'\n",
    "    gt_data_file = '../data/figmemes/cot_samples_gt.tsv'\n",
    "elif dataset_name == 'figmemes_cot_few_shot':\n",
    "    img_prompt_respond_file = '../data/figmemes/filtered_meme_configs_figmemes_cot_few_shot.json'\n",
    "    gt_data_file = '../data/figmemes/cot_samples_gt.tsv'\n",
    "elif  dataset_name == 'memecap':\n",
    "    img_prompt_respond_file = '../data/memecap/filtered_meme_configs_5_attributes_memecap.json'\n",
    "\n",
    "# load predicted data\n",
    "meme_configs = []\n",
    "with open(img_prompt_respond_file, 'r', encoding='utf-8') as json_file:\n",
    "    meme_configs = json.load(json_file)\n",
    "len(meme_configs)\n",
    "\n",
    "# load ground truth data\n",
    "gt_data = pd.read_csv(gt_data_file, sep='\\t', index_col='img_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allusion</th>\n",
       "      <th>exaggeration</th>\n",
       "      <th>irony</th>\n",
       "      <th>anthrop</th>\n",
       "      <th>metaphor</th>\n",
       "      <th>contrast</th>\n",
       "      <th>year</th>\n",
       "      <th>arts</th>\n",
       "      <th>real</th>\n",
       "      <th>mixed</th>\n",
       "      <th>infograph</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>img_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1458964859691.jpg</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464007930878.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467472694126.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468935750176.jpg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470534047335.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470839669535.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472045568054.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472180356237.jpg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474915955788.png</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476202710205.jpg</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476396825243.jpg</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   allusion  exaggeration  irony  anthrop  metaphor  contrast  \\\n",
       "img_name                                                                        \n",
       "1458964859691.jpg         1             0      0        0         0         0   \n",
       "1464007930878.jpg         0             0      0        0         0         0   \n",
       "1467472694126.png         0             0      1        0         0         0   \n",
       "1468935750176.jpg         1             1      0        0         0         0   \n",
       "1470534047335.jpg         0             0      0        0         0         0   \n",
       "1470839669535.jpg         0             0      1        0         0         0   \n",
       "1472045568054.jpg         0             0      0        0         0         0   \n",
       "1472180356237.jpg         1             1      0        0         1         1   \n",
       "1474915955788.png         0             0      0        0         0         1   \n",
       "1476202710205.jpg         0             0      0        0         0         0   \n",
       "1476396825243.jpg         1             1      0        1         1         0   \n",
       "\n",
       "                   year  arts  real  mixed  infograph  \n",
       "img_name                                               \n",
       "1458964859691.jpg  2017     1     0      0          0  \n",
       "1464007930878.jpg  2020     0     1      0          0  \n",
       "1467472694126.png  2017     1     0      0          0  \n",
       "1468935750176.jpg  2019     1     0      0          0  \n",
       "1470534047335.jpg  2017     0     1      0          0  \n",
       "1470839669535.jpg  2017     1     0      0          0  \n",
       "1472045568054.jpg  2018     0     1      0          0  \n",
       "1472180356237.jpg  2017     0     0      1          0  \n",
       "1474915955788.png  2017     0     0      1          0  \n",
       "1476202710205.jpg  2019     1     0      0          0  \n",
       "1476396825243.jpg  2017     0     1      0          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gt_data.loc['01144951214.png'][:6].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label2vec(label_list: list):\n",
    "    labels = ['allusion', 'exaggeration', 'irony', 'anthrop', 'metaphor', 'contrast']\n",
    "    vec = np.zeros((1, len(labels)))\n",
    "    for label in label_list:\n",
    "        vec[0, labels.index(label)] = 1\n",
    "    return vec\n",
    "\n",
    "label2vec(['exaggeration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_dir': './data/figmemes/images/1458964859691.jpg',\n",
       " 'prompt': 'Tasks: \\n1. Extract the texts on the meme;\\n2. Explain the meme from three perspectives: the humor of the meme; how the meme conveys the humor; And, the emotion behind the meme;\\n3. Choose suitable literary devices from the given candidates;\\n4. Choose suitable emotional words from the given candidates\\n\\nThe context of the meme: {}\\n\\nEmotion labels: anger, fear, surprise, sadness, disgust, contempt, happiness, none\\n\\nLiterary devices: \\n**Allusion**: Referencing historical events, figures, symbols, art, literature or pop culture.\\n \\n**Exaggeration**: Similar to Hyperbole. Use of exaggerated terms for emphasis, including exaggerated visuals (including unrealistic features portraying minorities).\\n \\n**Irony**: Similar to Sarcasm. Use of words that convey a meaning that is the opposite of its usual meaning/mock someone or something with caustic or bitter use of words.\\n  \\n**Anthropomorphism**: Similar to Zoomorphism. Attributing human qualities to animals, objects, natural phenomena or abstract concepts or applying animal characteristics to humans in a way that conveys additional meaning. \\n \\n**Metaphor**: Similar to Simile. Implicit or explicit comparisons between two items or groups, attributing the properties of one thing to another. This category includes dehumanizing metaphors. \\n \\n**Contrast**: Comparison between two positions/people/objects (usually side-by-side).\\n**None**: No literary devices are applied to the meme.\\n\\nExamples of explanation of the meme:\\n1. The meme uses a scene from the classic TV show \"Dragnet\", where a serious character is talking to someone in a seemingly humorous and judgmental manner. The humor arises from the juxtaposition of the formal, old-fashioned speech with the modern concept of someone being \"high\" or under the influence of drugs. This contrast creates a humorous effect by placing a very serious, straight-laced character in a context that he seems out of touch with. (No literary device from above is used here, so it is \"None\")\\n2. The meme humorously contrasts the rigorous training of US Marines with an image of an older Russian woman casually carrying a heavy log. The humor lies in the exaggerated comparison, suggesting that what is intense training for US Marines is just a mundane task for a Russian woman. (The literary device \"Contrast\" is used here for comparing the rigorous training of US Marines with an older Russian woman)\\n3. The meme uses the popular internet character Pepe the Frog, depicted as Hillary Clinton with a pin reading \"Hillary 2016\". She is shown confidently sitting with Donald Trump, also in meme form, crying at her feet. The humor comes from the exaggerated and ironic portrayal of both characters, reflecting a political commentary on the 2016 U.S. Presidential election. (\"Anthropomorphism\" and  \"Exaggeration\" are used here to say that Hellary was going to win Trump easily)\\n\\nNow, based on the meme (image), the context of the meme, those examples, the emotion labels, and the definition of literary devices, write down the detected text and explanation of the meme. Then, choose one or multiple appropriate literary devices and emotional words. Follow the JSON format: \\n{\\n\"detected text\": \"string\",\\n\"explanation\": \"a string\",\\n\"emotion\": \"a string\",\\n\"literary device\": [\"word 1\", …],\\n\"emotion word\": [\"word 1\", …]\\n}',\n",
       " 'detected text': 'Choose life (30.19)',\n",
       " 'explanation': \"The meme shows a simplistic line drawing of a person with their arms raised, exuding positivity. Combined with the text 'Choose life,' it likely references a motivational or inspirational message. The number '(30.19)' might not be clear without context, but it hints at a specific verse, possibly from religious or philosophical texts, which adds depth to the message. The humor in the meme isn't overt but rather light-hearted and uplifting, conveying a sense of joy and positive encouragement.\",\n",
       " 'emotion': 'happiness',\n",
       " 'literary device': ['allusion'],\n",
       " 'emotion word': ['joy', 'positivity']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_configs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11, 6), (11, 6))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "gt = []\n",
    "for idx, meme_conf in enumerate(meme_configs):\n",
    "    predictions.append(label2vec(meme_conf['literary device']))\n",
    "    gt.append(gt_data.loc[meme_conf['image_dir'].split('/')[-1]][:6].tolist())\n",
    "\n",
    "predictions = np.array(predictions).squeeze()\n",
    "gt = np.array(gt)\n",
    "predictions.shape, gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 1., 1., 0., 0.],\n",
       "       [0., 1., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 1.],\n",
       "       [1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macro: 0.49302987197724035\n",
      "micro: 0.5909090909090909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.65      0.72        52\n",
      "           1       0.22      0.36      0.27        14\n",
      "\n",
      "    accuracy                           0.59        66\n",
      "   macro avg       0.50      0.51      0.49        66\n",
      "weighted avg       0.67      0.59      0.62        66\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('macro:', f1_score(gt.flatten(), predictions.flatten(), average='macro'))\n",
    "print('micro:', f1_score(gt.flatten(), predictions.flatten(), average='micro'))\n",
    "print(classification_report(gt.flatten(), predictions.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25         4\n",
      "           1       0.25      0.33      0.29         3\n",
      "           2       0.14      0.50      0.22         2\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.17      0.50      0.25         2\n",
      "\n",
      "   micro avg       0.22      0.36      0.27        14\n",
      "   macro avg       0.22      0.43      0.28        14\n",
      "weighted avg       0.20      0.36      0.25        14\n",
      " samples avg       0.26      0.25      0.23        14\n",
      "\n",
      "one\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25         4\n",
      "           1       0.25      0.33      0.29         3\n",
      "           2       0.14      0.50      0.22         2\n",
      "           3       0.50      1.00      0.67         1\n",
      "           4       1.00      0.00      0.00         2\n",
      "           5       0.17      0.50      0.25         2\n",
      "\n",
      "   micro avg       0.22      0.36      0.27        14\n",
      "   macro avg       0.38      0.43      0.28        14\n",
      "weighted avg       0.35      0.36      0.25        14\n",
      " samples avg       0.26      0.61      0.23        14\n",
      "\n",
      "\n",
      "zero\n",
      "micro\n",
      "27.027027027027025\n",
      "\n",
      "macro\n",
      "27.91005291005291\n",
      "\n",
      "weighted\n",
      "24.77324263038549\n",
      "\n",
      "samples\n",
      "22.727272727272727\n",
      "\n",
      "one\n",
      "micro\n",
      "27.027027027027025\n",
      "\n",
      "macro\n",
      "27.91005291005291\n",
      "\n",
      "weighted\n",
      "24.77324263038549\n",
      "\n",
      "samples\n",
      "22.727272727272727\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def gimme_f1s(y_true, y_pred):\n",
    "    print('zero')\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred, zero_division=0))\n",
    "    print('one')\n",
    "    print(classification_report(y_true=y_true, y_pred=y_pred, zero_division=1))\n",
    "    print()\n",
    "    print('zero')\n",
    "    f1s = ['micro', 'macro', 'weighted', 'samples']\n",
    "    for score in f1s:\n",
    "        f1 = f1_score(y_true=y_true, y_pred=y_pred, zero_division=0, average=score)*100\n",
    "        print(score)\n",
    "        print(f1)\n",
    "        print()\n",
    "    print('one')\n",
    "    for score in f1s:\n",
    "        f1 = f1_score(y_true=y_true, y_pred=y_pred, zero_division=1, average=score)*100\n",
    "        print(score)\n",
    "        print(f1)\n",
    "        print()\n",
    "\n",
    "gimme_f1s(gt, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
